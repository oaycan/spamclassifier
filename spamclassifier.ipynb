{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier\n",    
    "## Training Data\n",
    "The training data is described below and has 1000 rows. There is also a 500 row set of test data. These are functionally identical to the training data, they are just in a separate csv file to encourage you to split out your training and test data. You should consider how to best make use of all available data without overfitting, and to help produce an unbiased estimate for your classifier's accuracy.\n",
    "\n",
    "The cell below loads the training data into a variable called `training_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam training data set: (1000, 55)\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_spam = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam training data set:\", training_spam.shape)\n",
    "print(training_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your training set consists of 1000 rows and 55 columns. Each row corresponds to one email message. The first column is the _response_ variable and describes whether a message is spam `1` or ham `0`. The remaining 54 columns are _features_ that you will use to build a classifier. These features correspond to 54 different keywords (such as \"money\", \"free\", and \"receive\") and special characters (such as \":\", \"!\", and \"$\"). A feature has the value `1` if the keyword appears in the message and `0` otherwise.\n",
    "\n",
    "As mentioned there is also a 500 row set of *test data*. It contains the same 55 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam testing data set: (500, 55)\n",
      "[[1 0 0 ... 1 1 1]\n",
      " [1 1 0 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "print(\"Shape of the spam testing data set:\", testing_spam.shape)\n",
    "print(testing_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "Write all of the code for your classifier below this cell. There is some very rough skeleton code in the cell directly below. You may insert more cells below this if you wish, but you must not duplicate any cells as this can break the grading script.\n",
    "\n",
    "### Submission Requirements\n",
    "Your code must provide a variable with the name `classifier`. This object must have a method called `predict` which takes input data and returns class predictions. The input will be a single $n \\times 54$ numpy array, your classifier should return a numpy array of length $n$ with classifications. There is a demo in the cell below, and a test you can run before submitting to check your code is working correctly.\n",
    "\n",
    "Your code must run on our test machine in under 30 seconds. If you wish to train a more complicated model (e.g. neural network) which will take longer, you are welcome to save the model's weights as a file and then load these in the cell below so we can test it. You must include the code which computes the original weights, but this must not run when we run the notebook – comment out the code which actually executes the routine and make sure it is clear what we need to change to get it to run. Remember that we will be testing your final classifier on additional hidden data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.log_class_priors = 0\n",
    "        self.log_class_conditional_likelihoods = 0\n",
    "        \n",
    "    # main function for training\n",
    "    def train(self, alpha):\n",
    "        # inner function to create class priors\n",
    "        def estimate_log_class_priors(data):\n",
    "            # filter out our class labeled data \"y\"  which is in the first column\n",
    "            y = data[:,0]\n",
    "            \n",
    "            # create two arrays for two classes (num_C0:ham messages and num_C1:spam messages) \n",
    "            num_C0 = np.count_nonzero(y == 0)\n",
    "            num_C1 = np.count_nonzero(y == 1)\n",
    "            \n",
    "            # find the probability of class priors and take their logarithms\n",
    "            # P(C=0) -- class_priors_C0, P(C=1) -- class_priors_C1\n",
    "            class_priors_C0 = np.log(num_C0/(num_C0 + num_C1))\n",
    "            class_priors_C1 = np.log(1 - num_C0/(num_C0 + num_C1))\n",
    "            \n",
    "            # create an array including all class priors with length two\n",
    "            log_class_priors = np.array([class_priors_C0, class_priors_C1])\n",
    "\n",
    "            return log_class_priors\n",
    "        \n",
    "        # inner function to create class conditional likelihoods\n",
    "        def estimate_log_class_conditional_likelihoods(data, alpha):\n",
    "            # filter out our class labeled data \"y\" which is in the first column\n",
    "            # and create our input data\n",
    "            y = data[:,0]            \n",
    "            input_data = data[:, 1:]\n",
    "            \n",
    "            # detect the number of words and assign this to self.k\n",
    "            #self.k = len(data[0, 1:])\n",
    "                \n",
    "            # get row indices of each classes (0-ham & 1-spam msg) within our data\n",
    "            indices_C0 = np.nonzero(y == 0)\n",
    "            indices_C1 = np.nonzero(y == 1) \n",
    "            \n",
    "            # create our data for each classes (data_C0:ham messages and data_C1:spam messages)\n",
    "            data_C0 = input_data[indices_C0]\n",
    "            data_C1 = input_data[indices_C1]\n",
    "            \n",
    "            # calculate the frequency of each message for each of the classes\n",
    "            # within the whole training set\n",
    "            num_of_w_class0 = np.count_nonzero(data_C0 == 1, axis=0)\n",
    "            num_of_w_class1 = np.count_nonzero(data_C1 == 1, axis=0)\n",
    "            \n",
    "            # create an array for each class, that includes the probabilities of each keyword \n",
    "            # drawn from a bag of words and concatenate them into one array(theta)\n",
    "            prob_array_0 = np.log((num_of_w_class0 + alpha) / ((sum(num_of_w_class0) + self.k*alpha)))\n",
    "            prob_array_1 = np.log((num_of_w_class1 + alpha) / ((sum(num_of_w_class1) + self.k*alpha)))\n",
    "            theta = np.concatenate(([prob_array_0], [prob_array_1]), axis=0)\n",
    "            \n",
    "            return theta\n",
    "        \n",
    "        self.log_class_priors = estimate_log_class_priors(training_spam)\n",
    "        self.log_class_conditional_likelihoods = estimate_log_class_conditional_likelihoods(training_spam, alpha)\n",
    "        \n",
    "    def predict(self, new_data):     \n",
    "        prediction_matrix = 0\n",
    "        # matrix product of new_data and the transpose of log_class_conditional_likelihoods (∑ 𝑤i * log(𝜃𝑐,𝑤𝑖))\n",
    "        # by doing this matrix product we can greatly decrease the complexity of computation\n",
    "        pre_prediction_matrix = new_data@self.log_class_conditional_likelihoods.T\n",
    "\n",
    "        # Here we add P(C=c) to the above matrix so that we calculate the predictions of n_test_samples for 2 classes\n",
    "        prediction_matrix = np.array([pre_prediction_matrix[:, 0] + self.log_class_priors[0], \\\n",
    "                                      pre_prediction_matrix[:, 1] + self.log_class_priors[1]])\n",
    "\n",
    "        class_predictions = np.where(prediction_matrix[1, :] > prediction_matrix[0, :], 1, 0)\n",
    "        return class_predictions    \n",
    "\n",
    "def create_classifier(alpha):\n",
    "    classifier = SpamClassifier(k=54)\n",
    "    classifier.train(alpha)\n",
    "    return classifier\n",
    "\n",
    "classifier = create_classifier(alpha=236)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Estimate\n",
    "In the cell below there is a function called `my_accuracy_estimate()` which returns `0.5`. Before you submit the assignment, write your best guess for the accuracy of your classifier into this function, as a percentage between `0` and `1`. So if you think you will get 80% of inputs correct, return the value `0.8`. This will form a small part of the marking criteria for the assignment, to encourage you to test your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy_estimate():\n",
    "    return 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all of the code for your classifier above this cell.\n",
    "\n",
    "### Testing Details\n",
    "Your classifier will be tested against some hidden data from the same source as the original. The accuracy (percentage of classifications correct) will be calculated, then benchmarked against common methods. At the very high end of the grading scale, your accuracy will also be compared to the best submissions from other students (in your own cohort and others!). Your estimate from the cell above will also factor in, and you will be rewarded for being close to your actual accuracy (overestimates and underestimates will be treated the same).\n",
    "\n",
    "#### Test Cell\n",
    "The following code will run your classifier against the provided test data. To enable it, set the constant `SKIP_TESTS` to `False`.\n",
    "\n",
    "The original skeleton code above classifies every row as ham, but once you have written your own classifier you can run this cell again to test it. So long as your code sets up a variable called `classifier` with a method called `predict`, the test code will be able to run. \n",
    "\n",
    "Of course you may wish to test your classifier in additional ways, but you *must* ensure this version still runs before submitting.\n",
    "\n",
    "**IMPORTANT**: you must set `SKIP_TESTS` back to `True` before submitting this file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_TESTS = True\n",
    "\n",
    "if not SKIP_TESTS:\n",
    "    testing_spam = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\").astype(np.int)\n",
    "    test_data = testing_spam[:, 1:]\n",
    "    test_labels = testing_spam[:, 0]\n",
    "\n",
    "    predictions = classifier.predict(test_data)\n",
    "    accuracy = np.count_nonzero(predictions == test_labels)/test_labels.shape[0]\n",
    "    print(f\"Accuracy on test data is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59d6bceb43ad854b001cc67cf0fc07f9",
     "grade": false,
     "grade_id": "cell-ce83a675162843d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Make sure you follow the instructions on the assignment page to submit your video.\n",
      "Failing to include this could result in an overall grade of zero for both parts.\n",
      "\n",
      "All checks passed. When you are ready to submit, upload the notebook and readme file to the\n",
      "assignment page, without changing any filenames.\n",
      "\n",
      "If you need to submit multiple files, you can archive them in a .zip file. (No other format.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "fail = False;\n",
    "\n",
    "if not SKIP_TESTS:\n",
    "    fail = True;\n",
    "    print(\"You must set the SKIP_TESTS constant to True in the cell above.\")\n",
    "    \n",
    "p3 = pathlib.Path('./spamclassifier.ipynb')\n",
    "if not p3.is_file():\n",
    "    fail = True\n",
    "    print(\"This notebook file must be named spamclassifier.ipynb\")\n",
    "    \n",
    "if \"create_classifier\" not in dir():\n",
    "    fail = True;\n",
    "    print(\"You must include a function called create_classifier.\")\n",
    "\n",
    "if \"my_accuracy_estimate\" not in dir():\n",
    "    fail = True;\n",
    "    print(\"You must include a function called my_accuracy_estimate.\")\n",
    "else:\n",
    "    if my_accuracy_estimate() == 0.5:\n",
    "        print(\"Warning:\")\n",
    "        print(\"You do not seem to have provided an accuracy estimate, it is set to 0.5.\")\n",
    "        print(\"This is the actually the worst possible accuracy – if your classifier\")\n",
    "        print(\"got 0.1 then it could invert its results to get 0.9!\")\n",
    "    \n",
    "print(\"INFO: Make sure you follow the instructions on the assignment page to submit your video.\")\n",
    "print(\"Failing to include this could result in an overall grade of zero for both parts.\")\n",
    "print()\n",
    "\n",
    "if fail:\n",
    "    sys.stderr.write(\"Your submission is not ready! Please read and follow the instructions above.\")\n",
    "else:\n",
    "    print(\"All checks passed. When you are ready to submit, upload the notebook and readme file to the\")\n",
    "    print(\"assignment page, without changing any filenames.\")\n",
    "    print()\n",
    "    print(\"If you need to submit multiple files, you can archive them in a .zip file. (No other format.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "badbc892f539e03ad0acdb369f7e0993",
     "grade": true,
     "grade_id": "cell-b64bc40ab6485b50",
     "locked": true,
     "points": 100,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell. Please do not modify or delete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
